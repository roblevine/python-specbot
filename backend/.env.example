# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Frontend URL for CORS
FRONTEND_URL=http://localhost:5173

# Logging
LOG_LEVEL=DEBUG

# Debug Mode - Set to true to expose detailed error messages in API responses
# WARNING: Only use in development! Never enable in production!
DEBUG=true

# Conversation Storage
# Path to the JSON file for storing conversations (relative to backend/ or absolute)
STORAGE_PATH=data/conversations.json

# =============================================================================
# Provider API Keys
# =============================================================================
# At least one provider API key must be configured

# OpenAI API Key
OPENAI_API_KEY=your-api-key-here

# Anthropic API Key (Optional - enables Claude models)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# =============================================================================
# Model Configuration (UNIFIED FORMAT - RECOMMENDED)
# =============================================================================
# Configure all models in a single MODELS environment variable.
# Each model must have a "provider" field to identify its provider.
# Exactly one model must have "default": true across all providers.
# Models are automatically filtered based on which API keys are configured.

# Single provider setup (OpenAI only):
# MODELS='[{"id":"gpt-3.5-turbo","name":"GPT-3.5 Turbo","description":"Fast and efficient for most tasks","provider":"openai","default":true}]'

# Multi-provider setup (recommended):
MODELS='[
  {"id": "gpt-4", "name": "GPT-4", "description": "Most capable model for complex reasoning", "provider": "openai", "default": false},
  {"id": "gpt-3.5-turbo", "name": "GPT-3.5 Turbo", "description": "Fast and efficient for most tasks", "provider": "openai", "default": true},
  {"id": "claude-3-5-sonnet-20241022", "name": "Claude 3.5 Sonnet", "description": "Most capable Claude model for complex tasks", "provider": "anthropic", "default": false},
  {"id": "claude-3-haiku-20240307", "name": "Claude 3 Haiku", "description": "Fast and efficient for simple tasks", "provider": "anthropic", "default": false}
]'

# =============================================================================
# Legacy Model Configuration (DEPRECATED - for backward compatibility)
# =============================================================================
# The separate OPENAI_MODELS and ANTHROPIC_MODELS variables are still supported
# but not recommended. If MODELS is set, these legacy variables are ignored.

# OpenAI Models (legacy format):
# OPENAI_MODELS='[{"id":"gpt-3.5-turbo","name":"GPT-3.5 Turbo","description":"Fast and efficient for most tasks","default":true}]'

# Anthropic Models (legacy format):
# ANTHROPIC_MODELS='[{"id":"claude-3-5-sonnet-20241022","name":"Claude 3.5 Sonnet","description":"Most capable Claude model for complex tasks","provider":"anthropic","default":false}]'
