# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Frontend URL for CORS
FRONTEND_URL=http://localhost:5173

# Logging
LOG_LEVEL=DEBUG

# Debug Mode - Set to true to expose detailed error messages in API responses
# WARNING: Only use in development! Never enable in production!
DEBUG=true

# Conversation Storage
# Path to the JSON file for storing conversations (relative to backend/ or absolute)
STORAGE_PATH=data/conversations.json

# OpenAI Configuration
OPENAI_API_KEY=your-api-key-here

# Model Configuration (REQUIRED)
# Format: JSON array of model objects with id, name, description, and default
# Exactly one model must have "default": true
# Note: At least one model must be configured for the application to work

# Simple single model setup:
OPENAI_MODELS='[{"id":"gpt-3.5-turbo","name":"GPT-3.5 Turbo","description":"Fast and efficient for most tasks","default":true}]'

# Multi-model setup (enables model selection in UI):
# OPENAI_MODELS='[
#   {"id": "gpt-4", "name": "GPT-4", "description": "Most capable model for complex reasoning", "default": false},
#   {"id": "gpt-4-turbo", "name": "GPT-4 Turbo", "description": "Faster GPT-4 with latest knowledge", "default": false},
#   {"id": "gpt-3.5-turbo", "name": "GPT-3.5 Turbo", "description": "Fast and efficient for most tasks", "default": true},
#   {"id": "gpt-4o", "name": "GPT-4o", "description": "High performance multimodal model", "default": false}
# ]'
