# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Frontend URL for CORS
FRONTEND_URL=http://localhost:5173

# Logging
LOG_LEVEL=DEBUG

# Debug Mode - Set to true to expose detailed error messages in API responses
# WARNING: Only use in development! Never enable in production!
DEBUG=true

# OpenAI Configuration
OPENAI_API_KEY=your-api-key-here

# Single Model Configuration (simple setup)
# Uncomment to use a single model with automatic fallback configuration
OPENAI_MODEL=gpt-3.5-turbo

# Multi-Model Configuration (Feature 008: Model Selector)
# Uncomment and configure to enable model selection in the UI
# Format: JSON array of model objects with id, name, description, and default
# Exactly one model must have "default": true
# OPENAI_MODELS='[{"id":"gpt-4","name":"GPT-4","description":"Most capable model for complex reasoning tasks","default":true},{"id":"gpt-3.5-turbo","name":"GPT-3.5 Turbo","description":"Fast and efficient for most tasks","default":false}]'

# Example with more models:
# OPENAI_MODELS='[
#   {"id": "gpt-4", "name": "GPT-4", "description": "Most capable model for complex reasoning", "default": false},
#   {"id": "gpt-4-turbo", "name": "GPT-4 Turbo", "description": "Faster GPT-4 with latest knowledge", "default": false},
#   {"id": "gpt-3.5-turbo", "name": "GPT-3.5 Turbo", "description": "Fast and efficient for most tasks", "default": false},
#   {"id": "gpt-4o", "name": "GPT-4o", "description": "High performance multimodal model", "default": false},
#   {"id": "gpt-5", "name": "GPT-5", "description": "Next generation model", "default": true},
#   {"id": "gpt-5-codex", "name": "GPT-5 Codex", "description": "Next generation model specialized for coding", "default": false}
# ]'
