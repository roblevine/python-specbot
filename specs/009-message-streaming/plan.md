# Implementation Plan: Message Streaming for Real-Time LLM Responses

**Branch**: `009-message-streaming` | **Date**: 2026-01-13 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/009-message-streaming/spec.md`

## Summary

Implement real-time streaming of LLM responses to provide users with immediate feedback as AI-generated content is produced. This feature transforms the current synchronous request-response pattern into a progressive streaming experience, where users see tokens appear in real-time as they are generated by the LLM. The implementation uses Server-Sent Events (SSE) for backend-to-frontend streaming, LangChain's async streaming capabilities, and reactive Vue components for token-by-token display.

**Primary Requirement**: Users must see LLM responses progressively as they are generated, with first token visible within 1 second and smooth token-by-token display.

**Technical Approach**: Extend the existing POST /api/v1/messages endpoint to support streaming via SSE, use LangChain's `astream` method instead of `ainvoke`, and update the frontend to consume SSE streams with EventSource API and display tokens reactively in Vue components.

## Technical Context

**Language/Version**: Python 3.13 (backend), JavaScript ES6+ (frontend)
**Primary Dependencies**:
- Backend: FastAPI 0.115.0, LangChain, langchain-openai, Pydantic 2.10.0
- Frontend: Vue 3.4.0 (Composition API), Vite 5.0.0
**Storage**: Browser LocalStorage (schema v1.1.0) - no changes required for streaming
**Testing**:
- Backend: pytest (unit, integration, contract tests)
- Frontend: Vitest (unit, integration), Playwright (e2e)
**Target Platform**: Web application (Linux backend server, modern browsers)
**Project Type**: Web (frontend + backend)
**Performance Goals**:
- First token visible within 1 second of request
- Each token rendered within 100ms of receipt
- Support 100 concurrent streaming sessions
- 95% streaming success rate
**Constraints**:
- Must maintain backward compatibility with existing conversation history format
- Must work within current LocalStorage persistence model
- No breaking changes to existing API for non-streaming clients
- Must handle browser EventSource limitations (6 concurrent connections per domain)
**Scale/Scope**:
- Single new streaming endpoint (or extend existing endpoint)
- ~5-10 frontend components affected (ChatArea, MessageBubble, useMessages composable)
- ~3-5 backend modules affected (messages route, llm_service, schemas)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### I. API-First Design ✅
- **Status**: PASS
- **Evidence**: Will define streaming API contract in Phase 1 (contracts/streaming-api.yaml) before implementation
- **Note**: Streaming endpoint will be specified with SSE format, event types, error handling

### II. Modular Architecture ✅
- **Status**: PASS
- **Evidence**: Feature extends existing modules without creating new coupling
  - Backend: Extends message service and LLM service with streaming variants
  - Frontend: Extends useMessages composable and ChatArea components
- **Note**: Streaming logic encapsulated in separate functions (e.g., `stream_ai_response` alongside existing `get_ai_response`)

### III. Test-First Development (NON-NEGOTIABLE) ✅
- **Status**: PASS (will be enforced in implementation)
- **Plan**:
  1. Write contract tests for streaming endpoint (capture SSE stream format)
  2. Write integration tests for streaming flow (backend → frontend)
  3. Write unit tests for token accumulation, error handling, state management
  4. Get user approval on test scenarios before implementation
  5. Verify tests FAIL before implementation
- **Note**: Contract tests critical for SSE format validation (event structure, chunking, completion signals)

### IV. Integration & Contract Testing (NON-NEGOTIABLE) ✅
- **Status**: PASS (will be enforced in implementation)
- **Plan**:
  - Consumer-driven contract tests for streaming endpoint
  - Validate both SSE request format (headers, connection) and response format (event structure, data payload)
  - Snapshot SSE event sequences for regression testing
  - Backend replay tests to verify stream compatibility
- **Note**: Streaming adds complexity - contract tests ensure frontend/backend stay synchronized on event format

### V. Observability & Debuggability ✅
- **Status**: PASS
- **Plan**:
  - Log stream start/stop/error events
  - Track streaming metrics (tokens/sec, stream duration, success rate)
  - Include correlation IDs for stream debugging
  - Log partial responses on interruption
- **Note**: Structured logging already exists, will extend for streaming events

### VI. Simplicity & YAGNI ✅
- **Status**: PASS with justification
- **Approach**:
  - Use standard SSE (Server-Sent Events) - proven, simple, browser-native
  - No WebSockets (overkill for unidirectional streaming)
  - No custom protocol (SSE handles reconnection, event IDs automatically)
  - Extend existing endpoint rather than create separate streaming infrastructure
- **Justification**: SSE is simplest solution for server→client streaming. No need for bidirectional communication.

### VII. Versioning & Breaking Changes ✅
- **Status**: PASS - No breaking changes
- **Plan**:
  - Streaming support added as optional capability (Accept: text/event-stream header)
  - Existing clients continue to work with synchronous responses
  - LocalStorage schema unchanged (v1.1.0 sufficient)
- **Note**: Backward compatible - clients choose streaming via request headers

### VIII. Incremental Delivery & Thin Slices (NON-NEGOTIABLE) ✅
- **Status**: PASS
- **Implementation Order** (thin vertical slices):
  1. **Slice 1 (P1 - MVP)**: Basic streaming for new messages
     - Backend: SSE endpoint + LangChain astream
     - Frontend: EventSource consumption + basic token display
     - **Demo**: Send message, see response stream token-by-token
  2. **Slice 2 (P2)**: Streaming status indicators
     - Frontend: Visual indicators (animated cursor, "generating" label)
     - **Demo**: Clear distinction between streaming vs complete states
  3. **Slice 3 (P3)**: Error handling and interruptions
     - Backend: Graceful error events in stream
     - Frontend: Error states, partial response preservation
     - **Demo**: Simulate network interruption, see error handling
- **Note**: Each slice is independently testable, demonstrable, and deployable

### IX. Living Architecture Documentation ✅
- **Status**: PASS (will be enforced in implementation)
- **Plan**:
  - Update architecture.md with streaming data flow
  - Add SSE communication pattern to architecture diagram
  - Document streaming endpoint in API Routes Layer section
  - Add ADR (Architectural Decision Record) for SSE over WebSockets choice
- **Note**: Streaming changes data flow significantly - architecture doc must reflect this

### Architecture Documentation Plan
This feature introduces streaming communication between backend and frontend, which is a significant architectural change. Will update `architecture.md` with:
- **Current Architecture** section:
  - Add SSE streaming endpoint to API Routes Layer
  - Update data flow diagram to show streaming path alongside synchronous path
  - Document EventSource usage in frontend API Client
  - Add streaming state management to State Management section
- **Technology Stack** section:
  - Add Server-Sent Events (SSE) as communication protocol
  - Document LangChain astream usage
  - Note browser EventSource API requirement
- **ADR** (Architectural Decision Record):
  - **Decision**: Use SSE over WebSockets for streaming
  - **Rationale**: Unidirectional server→client streaming, simpler than WebSockets, browser-native, automatic reconnection
  - **Alternatives**: WebSockets (overkill), HTTP polling (inefficient), chunked transfer encoding (complex)

## Project Structure

### Documentation (this feature)

```text
specs/009-message-streaming/
├── plan.md              # This file (/speckit.plan command output)
├── research.md          # Phase 0 output - SSE best practices, LangChain streaming patterns
├── data-model.md        # Phase 1 output - Streaming message entity, state transitions
├── quickstart.md        # Phase 1 output - How to test streaming locally
├── contracts/           # Phase 1 output - streaming-api.yaml (SSE format)
└── checklists/
    └── requirements.md  # Specification quality checklist (completed)
```

### Source Code (repository root)

```text
# Web application structure (frontend + backend)
backend/
├── src/
│   ├── models/           # (unused currently - no persistence)
│   ├── services/
│   │   ├── llm_service.py       # ✏️ MODIFY: Add stream_ai_response() using astream
│   │   └── message_service.py   # ✏️ MODIFY: Add streaming validation if needed
│   ├── api/
│   │   └── routes/
│   │       └── messages.py      # ✏️ MODIFY: Add streaming support via StreamingResponse
│   ├── schemas.py        # ✏️ MODIFY: Add streaming event schemas
│   ├── middleware/       # (no changes expected)
│   ├── config/           # (no changes expected)
│   └── utils/
│       └── logger.py     # ✏️ MODIFY: Add streaming-specific log functions
└── tests/
    ├── contract/
    │   └── test_message_api_contract.py  # ✏️ MODIFY: Add streaming contract tests
    ├── integration/
    │   └── test_streaming_flow.py        # ➕ CREATE: End-to-end streaming tests
    └── unit/
        └── test_llm_service.py            # ✏️ MODIFY: Add tests for stream_ai_response

frontend/
├── src/
│   ├── components/
│   │   ├── ChatArea/
│   │   │   ├── ChatArea.vue       # ✏️ MODIFY: Handle streaming messages
│   │   │   └── MessageBubble.vue  # ✏️ MODIFY: Show streaming indicator, accumulate tokens
│   │   ├── InputArea/
│   │   │   └── InputArea.vue      # ✏️ MODIFY: Disable input during streaming
│   │   └── StatusBar/
│   │       └── StatusBar.vue      # ✏️ MODIFY: Show "Streaming..." status
│   ├── services/
│   │   └── apiClient.js           # ✏️ MODIFY: Add streamMessage() using EventSource
│   ├── state/
│   │   ├── useMessages.js         # ✏️ MODIFY: Add streaming state (isStreaming, partialMessage)
│   │   └── useAppState.js         # ✏️ MODIFY: Add streaming status states
│   ├── storage/
│   │   ├── LocalStorageAdapter.js # (no changes - save completed streamed messages)
│   │   └── StorageSchema.js       # (no changes - v1.1.0 sufficient)
│   └── utils/
│       └── logger.js              # ✏️ MODIFY: Add streaming-specific log functions
└── tests/
    ├── unit/
    │   └── useMessages.spec.js     # ✏️ MODIFY: Add streaming state tests
    ├── integration/
    │   └── streaming-flow.test.js  # ➕ CREATE: Test SSE consumption and display
    └── e2e/
        └── streaming-e2e.test.js   # ➕ CREATE: Test full streaming user journey
```

**Structure Decision**: Extends existing web application structure (frontend + backend). No new directories required - streaming capabilities integrated into existing modules. This maintains architectural consistency and avoids complexity from separate streaming infrastructure.

## Complexity Tracking

*No constitutional violations requiring justification. All gates passed.*

## Phase 0: Research & Unknowns

**Status**: Ready to begin

**Research Topics**:
1. FastAPI Server-Sent Events implementation best practices
2. LangChain async streaming (`astream`) usage patterns and error handling
3. Browser EventSource API capabilities, limitations, and error handling
4. SSE message format standards (event types, data encoding, completion signals)
5. Vue reactivity patterns for real-time token accumulation
6. Concurrent streaming session limits and resource management
7. Streaming error recovery patterns (reconnection, partial response handling)

**Output**: `research.md` documenting findings and technical decisions

## Constitution Check - Post-Design Re-Evaluation

*Re-evaluated after Phase 1 design completion*

All constitutional principles remain satisfied:

### I. API-First Design ✅
- **Status**: PASS
- **Evidence**: `contracts/streaming-api.yaml` created with complete OpenAPI specification
- **Deliverable**: SSE event format, request/response schemas, error codes all defined

### II. Modular Architecture ✅
- **Status**: PASS
- **Evidence**: Design maintains module boundaries, no new coupling introduced
- **Note**: Streaming functions are additions, not replacements (e.g., `stream_ai_response` alongside `get_ai_response`)

### III. Test-First Development (NON-NEGOTIABLE) ✅
- **Status**: PASS (ready for enforcement in implementation)
- **Evidence**: Contract tests specified in contracts/, test scenarios identified in quickstart.md
- **Note**: Implementation phase must follow TDD workflow

### IV. Integration & Contract Testing (NON-NEGOTIABLE) ✅
- **Status**: PASS
- **Evidence**: SSE event format fully specified for contract testing
- **Note**: Contract tests will capture SSE event sequences as snapshots

### V. Observability & Debuggability ✅
- **Status**: PASS
- **Evidence**: quickstart.md includes debugging guide, log formats specified in research.md
- **Note**: Structured logging patterns documented for streaming events

### VI. Simplicity & YAGNI ✅
- **Status**: PASS
- **Evidence**: research.md documents SSE as simplest solution, alternatives rejected with rationale
- **Note**: No speculative features added beyond requirements

### VII. Versioning & Breaking Changes ✅
- **Status**: PASS
- **Evidence**: contracts/streaming-api.yaml shows backward compatibility (Accept header opt-in)
- **Note**: Existing clients unaffected, no schema version bump required

### VIII. Incremental Delivery & Thin Slices (NON-NEGOTIABLE) ✅
- **Status**: PASS
- **Evidence**: Three thin slices defined (P1: basic streaming, P2: indicators, P3: errors)
- **Note**: Each slice deliverable independently as per plan.md

### IX. Living Architecture Documentation ✅
- **Status**: PASS (will be enforced in implementation)
- **Evidence**: Plan specifies architecture.md updates, ADR for SSE choice documented in research.md
- **Note**: Implementation phase must update architecture.md

**Post-Design Constitutional Compliance**: ✅ ALL PRINCIPLES SATISFIED

---

## Phase 1: Design & Contracts

**Status**: ✅ COMPLETE

**Deliverables** (✅ Complete):
1. ✅ **data-model.md**: Streaming message entity, state transitions (streaming → complete → error)
   - StreamingMessage entity with attributes and validation rules
   - StreamEvent protocol specification (token, complete, error)
   - StreamingState composable state definition
   - State machine diagram with transitions
   - Data flow diagrams (happy path and error path)

2. ✅ **contracts/streaming-api.yaml**: OpenAPI 3.0 specification for SSE endpoint
   - POST /api/v1/messages with SSE support
   - Request format (Accept: text/event-stream header)
   - Event structure (TokenEvent, CompleteEvent, ErrorEvent schemas)
   - Data payload format (JSON in SSE data field)
   - Error codes and response schemas
   - Example requests and responses

3. ✅ **quickstart.md**: Comprehensive local testing guide
   - Environment setup and prerequisites
   - Step-by-step backend startup instructions
   - curl commands for testing SSE streams
   - Frontend testing with browser DevTools
   - Debugging guide with common issues and solutions
   - Performance benchmarks and troubleshooting

4. ✅ **research.md**: Technical research findings
   - FastAPI StreamingResponse patterns
   - LangChain astream() usage
   - Browser EventSource API capabilities
   - SSE message format standards
   - Vue reactivity patterns
   - Concurrent streaming session limits
   - Error recovery strategies

**Agent Context Update**: ✅ COMPLETE - Ran `.specify/scripts/bash/update-agent-context.sh claude` to update CLAUDE.md with streaming technologies.

## Phase 2: Task Generation

**Status**: Not started (separate /speckit.tasks command)

**Note**: This plan command stops after Phase 1. Task generation is done via `/speckit.tasks` command, which will:
- Break down implementation into atomic tasks
- Order tasks by dependencies
- Create tasks.md with TDD workflow for each task

---

**Next Steps After This Command**:
1. Review this plan for technical accuracy
2. Run Phase 0 research (automated by this command)
3. Run Phase 1 design generation (automated by this command)
4. Review generated contracts and data model
5. Run `/speckit.tasks` to generate implementation tasks
6. Begin TDD implementation of Slice 1 (P1 - MVP)
